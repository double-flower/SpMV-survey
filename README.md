<div align="center">
  <h2><i>A Systematic Survey of Sparse Matrix Vector Multiplication</i></h2> 
</div>

<div align="center">
<b>Jianhua Gao</b><sup>1</sup>,
<b>Bingjie Liu</b><sup>2</sup>,
<b>Weixing Ji</b><sup>1</sup>,
<b>Hua Huang</b><sup>1</sup>
</div>

<div align="center">
<sup>1</sup>School of Artificial Intelligence, Beijing Normal University
</div>
<div align="center">
<sup>2</sup>School of Computer Science and Technology, Beijing Institute of Technology
</div>

We present a systematic survey of sparse matrix-vector multiplication (SpMV).

## Content
- [Papers](#papers)
  - [Survey](#survey)
  - [Sparse Compression Formats](#sparse-compression-formats)
  - [Auto-Tuning Based Algorithm](auto-tuning-based-algorithm)
  - [Machine-Learning Based Algorithm](machine-learning-based-algorithm)
  - [Mixed Precision Based Optimization](#mixed-Precision-based-optimization)
  - [Architecture Oriented Optimization](#architecture-oriented-optimization)

  
- [Citation](#citation)


## Survey
- **A Survey on Performance Modelling and Optimization Techniques for SpMV on GPUs**.
   *Ms. Aditi V. Kulkarni, Prof. C. R. Barde. International Journal of Computer Science and Information Technologies (IJCSIT), 2014* [[pdf](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=eeb465ba9655a5a0c638e15fe2421c5d9a708d46)] ![](https://img.shields.io/badge/IJCSIT2014-orange)
- **A Survey of Sparse Matrix-Vector Multiplication Performance on Large Matrices**. *Max Grossman, Christopher Thiele, Mauricio Araya-Polo, Florian Frank, Faruk O. Alpak, Vivek Sarkar. arXiv, 2016* [[pdf](https://arxiv.org/pdf/1608.00636)] ![](https://img.shields.io/badge/Arxiv2016-orange)
- **Sparse Matrix-Vector Multiplication on GPGPUs**. *Salvatore Filippone, Valeria Cardellini, Davide Barbieri, Alessandro Fanfarillo, ACM Transactions on Mathematical Software (TOMS), 2017* [[DOI](https://dl.acm.org/doi/10.1145/3017994)] ![](https://img.shields.io/badge/TOMS2017-orange)
- **Research on Performance Optimization for Sparse Matrix-Vector Multiplication in Multi/Many-core Architecture**. *Qihan Wang, Mingliang Li, Jianming Pang, Di Zhu, in 2020 2nd International Conference on Information Technology and Computer Application (ITCA). IEEE, 2020* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9422076)] ![](https://img.shields.io/badge/ITCA2020-orange)
- **A Survey of Accelerating Parallel Sparse Linear Algebra**. *Guoqing Xiao, Chuanghui Yin, Tao Zhou, Xueqi Li, Yuedan Chen, Kenli Li, ACM Computing Surveys (ACM Comput Surv), 2023* [[DOI](https://dl.acm.org/doi/10.1145/3604606)] ![](https://img.shields.io/badge/ACMComputSurv2023-orange)

## Sparse Compression Formats
### Basic Compression Formats
- **Data structures to vectorize CG algorithms for general sparsity patterns**. *Gaia Valeria Paolini, Giuseppe Radicati Di Brozolo, BIT Numerical Mathematics(BIT Numer. Math), 1989* [[DOI](https://link.springer.com/article/10.1007/BF01932741)]
- **Sparse matrix vector multiplication techniques on the IBM 3090 VF**. *A. Peters, Parallel Computing, 1991* [[DOI](https://www.sciencedirect.com/science/article/abs/pii/S0167819105800079)]
- **SPARSKIT: A Basic Took Kit for Sparse Matrix Computations, Version 2**. *Youcef Saad, 1994* [[pdf](https://www.finley-lab.com/files/gau19/exercises/exercise-sparskit/sparskit-v2.pdf)] ![](https://img.shields.io/badge/Arxiv1994-orange)
- **Scan Primitives for GPU Computing**. *Shubhabrata Sengupta, Mark Harris, Yao Zhang, John D. Owens, in Proceedings of the 22nd ACM SIGGRAPH/EUROGRAPHICS Symposium, 2007* [[pdf](https://escholarship.org/content/qt8051p6nd/qt8051p6nd_noSplash_cdf4d7488f42df951707ca97e860123f.pdf)]
- **Sparse Matrix Computations on Manycore GPU’s**. *Michael Garland, in Proceedings of the 45th annual Design Automation Conference (DAC), 2008* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4555771)] ![](https://img.shields.io/badge/DAC2008-orange)

### New Compression Formats
#### Regular Slicing
- **The Sliced COO Format for Sparse Matrix-Vector Multiplication on CUDA-enabled GPUs**. *Hoang-Vu Dang, Bertil Schmidt, Proceedings of the International Conference on Computational Science(ICCS), 2012* [[pdf](https://pdf.sciencedirectassets.com/280203/1-s2.0-S1877050912X00036/1-s2.0-S1877050912001287/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEKD%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIA3mbg38oZkOfdwWyUCXm1t1E87ZEM34vjwWVr9wgRFZAiEAqFP8FbkBYfhel7NqcTYt%2BxqNVTXQRQOUvhB%2FUAAF2M4qugUIif%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDGUJGG%2FttwUgdR%2BZpyqOBURWdhDppaUWBl1iQ6%2FfYJSMYpHqrFgsxfVSDaoJQX%2F6DXUEGuV9vMR2M1jtNj%2FMIhRtpGkDmM300CIDtYtxk1GMaUoY%2BR50tF7loJQU9s2fEXXNDs4WflLwkS8lzufV5liMWbHj8tXq7EbIOQ9R6QE9dIThpxv2e4e9RofhPO6%2BbnfPlLKKpI%2FSfLNXRMpwfaeSdjkxdAWWr7omtVwL5IEmpk7tQjad6RBH9bcUcpElapd9umqlwEHBVHRRTMN9wJhGnIWM%2BnljropWr2jSv30x2KinhiG36qYswV7PaeH9Q%2FwJ7QEqWml4WXBM8FITER4PYUxkMsxKYf8vYGUr4p7mIi0P3RZCh%2FbuUwncRTy2akhC3Vx7PnHJqopfR%2BsbRkmiA6lRanbQQQQukP35VAV%2FT1w%2BcxOHWGVjzbKfb80EYVjTAAEwJrlxc8u2iCUWuWRyJqlqwb7LGFTDSFz4PEFXDfS3%2BOEQOBqu3VD%2Bc5WYowxo1X3Snz9ToI5gWqloik0K6ZxwH8ds0J%2B0jAc0yspxdY5kidNkx55enTFen6%2F417K1u1tPnc5slSYaFBWPZGR55v5XzLMEtzwaPCYShXGdZtIFtrYie7tpmJVCUr0DCxH3ZOoobP74nDTnChRUXZA8veCjH4o%2F%2FoGDWHRhFehpvK0qTVqUJ7SYCgZ45PV3077RK1q0o6htw3qJeUDl75ceJVQOyQ3J%2B1%2BtdVAu53dWxO403sYYZ1j0sRGRuUEV0DiDHRqJLL3huwHcjHnVgMjNpkaayidPF08pDWUNHh0YqQE5%2FybD5nVAFhja3%2F%2BiIHHtgri8hk%2F9JQ4KFwMtrb4bKl%2F1SntZoaml2bVaWSxPL8PJyiVBrtVIWSXNwTCe9P27BjqxAc3Fjo%2FzcZYTznWVgDcmTlVKta%2FoSRX%2BuH3WEKUL%2BnOjf7Zqi%2FB6iC%2FUdIbIkug%2B9CHYfooIOiT5fKEwQ2pkO%2B9MYhxfAvWhiD9gPsYfIw2w3Cc7T22PuZUUdO3NpDn9ti3%2Fk8TsHjVF7YEXpm%2F6smdNjVcR1ffgXe1pCNRR%2BwJpRv28krWld8XUEHD5yvuFlO%2FFDWLj%2BOAS3H4VY3QzPgixlLlTMn0%2FVrFoeMZkDdcyFg%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250109T074539Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYXJTEVK4U%2F20250109%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=0281f374273b55135056280db7813d1603678c33327f40cc29bc2acc2bb55030&hash=20fb158082664c615df16bf0d28a6077efd0c915c56fb9409ddf7ca2e72af0db&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1877050912001287&tid=spdf-bc42b010-b5cd-4e6f-ac74-dc8faddb6e25&sid=9dd20b14652bc94e2f281be53321891cc2e0gxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=0a0e59030454020154&rr=8ff2cf193ae006fa&cc=hk&kca=eyJrZXkiOiJBdDZ2UzcrVU0wQytudk9SNVFGZWNySTh6YThpZjZvYnJTVjIxU0FGdVR3amQzRjJ0Z3Z2a3g1MG5GNlRXS3JzODJob09DY0hUZGUxRi9HcjBpeVNzNUNIRHJTRjA4TnMya2l3bmcxbzRGcnBFMXNlQk4xNUhyYU9WTFVobGNnQUlncXpjZFBDQThoNU1Cek9NTnpmajlnYTNmcHlQcWg3bFlnVUFNYzdkTUlzWXhKViIsIml2IjoiOTgyYzVkNGY1ZjUwMzcxZjkxMjgwMzI1MThiMDdiMGUifQ==_1736408746540)] ![](https://img.shields.io/badge/ICCS2012-orange)
- **Vectorized Sparse Matrix Multiply for Compressed Row Storage Format**. *Eduardo F. D’Azevedo, Mark R. Fahey, Richard T. Mills, Computational Science(ICCS), 2005* [[DOI](https://link.springer.com/chapter/10.1007/11428831_13#preview)] ![](https://img.shields.io/badge/ICCS2005-orange)
- **Automatically Tuning Sparse Matrix-Vector Multiplication for GPU Architectures**. *Alexander Monakov, Anton Lokhmotov, Arutyun Avetisyan, High Performance Embedded Architectures and Compilers(HiPEAC), 2010* [[DOI](https://link.springer.com/chapter/10.1007/978-3-642-11515-8_10)] ![](https://img.shields.io/badge/HiPEAC2010-orange)
- **Three Storage Formats for Sparse Matrices on GPGPUs**. *Davide Barbieri, Alessandro Fanfarillo, Valeria Cardellini, Salvatore Filippone, Technical Report RR-15.6, 2015* [[pdf](https://art.torvergata.it/bitstream/2108/113393/1/DICII-RR-15.6.pdf)] ![](https://img.shields.io/badge/Arxiv2015-orange)
- **Sparse Matrix-vector Multiplication on GPGPU Clusters: A New Storage Format and a Scalable Implementation**. *Moritz Kreutzer, Georg Hager, Gerhard Wellein, Holger Fehske, Achim Basermann, Alan R. Bishop, 26th IEEE International Parallel and Distributed Processing Symposium(IPDPS), 2012* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6270844)] ![](https://img.shields.io/badge/IPDPS2012-orange)
- **A Unified Sparse Matrix Data Format for Efficient General Sparse Matrix-Vector Multiplication on Modern Processors with Wide SIMD Units**. *Moritz Kreutzer, Georg Hager, Gerhard Wellein, Holger Fehske, Alan R. Bishop, SIAM Journal on Scientific Computing(IPDPS), 2014* [[DIO](https://dl.acm.org/doi/abs/10.1137/130930352)] ![](https://img.shields.io/badge/IPDPS2014-orange)
- **Optimizing Sparse Matrix Vector Multiplication Using Diagonal Storage Matrix Format**. *Liang Yuan, Yunquan Zhang, Xiangzheng Sun, Ting Wang, The International Conference on High Performance Computing (HiPC),2010* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5581440)] ![](https://img.shields.io/badge/HiPC2010-orange)
- **CRSD: Application Specific Auto-tuning of SpMV for Diagonal Sparse Matrices**. *Xiangzheng Sun, Yunquan Zhang, Ting Wang, Guoping Long, Xianyi Zhang, Yan L,. Euro-Par 2011 Parallel Processing (Euro-Par), 2011* [[DOI](https://link.springer.com/chapter/10.1007/978-3-642-23397-5_32)] ![](https://img.shields.io/badge/EuroPar2011-orange)

#### Regular Blocking
- **SPARSKIT: A Basic Took Kit for Sparse Matrix Computations, Version 2**. *Y. Saad, 1994* [[pdf](https://ntrs.nasa.gov/api/citations/19910023551/downloads/19910023551.pdf)] ![](https://img.shields.io/badge/Arxiv1994-orange)
- **Improving Performance of Sparse Matrix-Vector Multiplication**. *Ali Pınar, Michael T. Heath, Proceedings of the 1999 ACM/IEEE Conference on Supercomputing (SC '99), 1999* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=1592673)] ![](https://img.shields.io/badge/SC1999-orange)
- **VBSF: a new storage format for SIMD sparse matrix–vector multiplication on modern processors**. *Yishui Li, Peizhen Xie, Xinhai Chen, Jie Liu, Bo Yang, Shengguo Li, Chunye Gong, Xinbiao Gan, Han Xu, The Journal of Supercomputing (J SUPERCOMPUT), 2020* [[DOI](https://link.springer.com/article/10.1007/s11227-019-02835-4)] ![](https://img.shields.io/badge/JSUPERCOMPUT2020-orange)
- **Automatic Performance Tuning of Sparse Matrix Kernels**. *Richard Wilson Vuduc, A dissertation submitted in partial, 2003* [[pdf](https://bebop.cs.berkeley.edu/pubs/vuduc2003-dissertation.pdf)] ![](https://img.shields.io/badge/Arxiv2003-orange)
- **An Efficient Two-Dimensional Blocking Strategy for Sparse Matrix-Vector Multiplication on GPUs**. *Arash Ashari, Naser Sedaghati, John Eisenlohr, P. Sadayappan, Proceedings of the 28th ACM international conference on Supercomputing (ICS),2014* [[DOI](https://dl.acm.org/doi/10.1145/2597652.2597678)] ![](https://img.shields.io/badge/ICS2014-orange)
- **A case study of streaming storage format for sparse matrices**. *Shweta Jain-Mendon, Ron Sass, 2012 International Conference on Reconfigurable Computing and FPGAs (ReConFig), 2012* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6416788)] ![](https://img.shields.io/badge/ReConFig2012-orange)
- **yaSpMV: Yet Another SpMV Framework on GPUs**. *Shengen Yan, Chao Li, Yunquan Zhang, Huiyang Zhou, ACM SIGPLAN Notices (ACM SIGPLAN Not), 2014* [[DOI](https://dl.acm.org/doi/10.1145/2692916.2555255)] ![](https://img.shields.io/badge/ACMSIGPLANNot2014-orange)
- **High-Performance Sparse Matrix-Vector Multiplication on GPUs for Structured Grid Computations**. *Jeswin Godwin, Justin Holewinski, P. Sadayappan, Proceedings of the 5th Annual Workshop on General Purpose Processing with Graphics Processing Units (GPGPU-5), 2012* [[DOI](https://dl.acm.org/doi/10.1145/2159430.2159436)] ![](https://img.shields.io/badge/GPGPU2012-orange)
- **Model-Driven Autotuning of Sparse Matrix-Vector Multiply on GPUs**. *Jee W. Choi, Amik Singh, Richard W. Vuduc, ACM SIGPLAN Notices (ACM SIGPLAN Not), 2010* [[pdf](https://vuduc.org/pubs/choi2010-gpu-spmv.pdf)] ![](https://img.shields.io/badge/ACMSIGPLANNot2010-orange)

#### Irregular Compressing
- **CSR5: An Efficient Storage Format for Cross-Platform Sparse Matrix-Vector Multiplication**. *Weifeng Liu, Brian Vinter, Proceedings of the 29th ACM on International Conference on Supercomputing (ICS), 2015*[[DOI]([https://arxiv.org/pdf/1503.05032](https://dl.acm.org/doi/10.1145/2751205.2751209))] [[code](https://github.com/weifengliu-ssslab/Benchmark_SpMV_using_CSR5)] ![](https://img.shields.io/badge/ICS2015-orange)
- **CSR2: A New Format for SIMD-Accelerated SpMV**. *Haodong Bian, Jianqiang Huang, Runting Dong, Lingbin Liu, Xiaoying Wang, IEEE/ACM International Symposium on Cluster Computing and the Grid (CCGRID), 2020* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9139720)] [[code](https://github.com/nulidangxueshen/CSR2)] ![](https://img.shields.io/badge/CCGRID2020-orange)
- **CSX: an extended compression format for spmv on shared memory systems**. *Kornilios Kourtis, Vasileios Karakasis, Georgios Goumas, Nectarios Koziris, ACM SIGPLAN Notices (ACM SIGPLAN Not), 2011* [[DOI](https://dl.acm.org/doi/abs/10.1145/2038037.1941587)] ![](https://img.shields.io/badge/ACMSIGPLANNot2011-orange)
- **ClSpMV: A Cross-Platform OpenCL SpMV Framework on GPUs**. *Bor-Yiing Su, Kurt Keutzer,Proceedings of the 26th ACM international conference on Supercomputing (ICS) ,2012* [[pdf](https://parlab.eecs.berkeley.edu/sites/all/parlab/files/clspMV-%20Keutzer.pdf)] ![](https://img.shields.io/badge/ICS2012-orange)

#### Bit/Byte Compressing
- **Accelerating sparse matrix computations via data compression**. *Jeremiah Willcock, Andrew Lumsdaine, Proceedings of the 20th annual international conference on Supercomputing (ICS), 2006* [[DOI](https://dl.acm.org/doi/abs/10.1145/1183401.1183444)] ![](https://img.shields.io/badge/ICS2006-orange)
- **Optimizing sparse matrix-vector multiplication using index and value compression**. *Kornilios Kourtis, Georgios Goumas, Nectarios Koziris, Proceedings of the 5th conference on Computing frontiers (CF),2008* [[pdf](http://www.cslab.ece.ntua.gr/~nkoziris/papers/cf08-spmv-kkourt.pdf)] ![](https://img.shields.io/badge/CF2008-orange)
- **A Family of Bit-Representation-Optimized Formats for Fast Sparse Matrix-Vector Multiplication on the GPU**. *Wai Teng Tang, Wen Jun Tan, Rick Siow Mong Goh, Stephen John Turner, Weng-Fai Wong, IEEE Transactions on Parallel and Distributed Systems (IEEE Trans Parallel Distrib Syst), 2015* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6895301)]
- **Towards a Universal FPGA Matrix-Vector Multiplication Architecture**. *Jeremiah Willcock, Andrew Lumsdaine, Annual IEEE Symposium on Field-Programmable Custom Computing Machines (FCCM), 2012* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6239784)] ![](https://img.shields.io/badge/FCCM2012-orange)

#### Hybrid Encoding
- **Efficient Sparse Matrix-Vector Multiplication on CUDA**. *Nathan Bell, Michael Garland, NVIDIA Technical Report (NVR),2008* [[DOI](https://research.nvidia.com/publication/2008-12_efficient-sparse-matrix-vector-multiplication-cuda)] ![](https://img.shields.io/badge/NVR2008-orange)
- **Load-Balancing Sparse Matrix Vector Product Kernels on GPUs**. *Hartwig Anzt, Terry Cojean, Yen-Chen Chen, Jack Dongarra, Goran Flegar, Pratik Nayak, Stanimire Tomov, Yuhsiang M.Tsai, Weichung Wang, ACM Transactions on Parallel Computing (TOPC), 2020* [[pdf](https://dl.acm.org/doi/pdf/10.1145/3380930)] [[code](https://ginkgo-project.github.io/)][[code](https://github.com/ginkgo-project/ginkgo)] [[code](https://github.com/ginkgo-project/ginkgo-data)] [[code](https://ginkgo-project.github.io/gpe/)] ![](https://img.shields.io/badge/TOPC2020-orange)
- **Acceleration of Conjugate Gradient Method for Circuit Simulation Using CUDA**. *Anirudh Maringanti, Viraj Athavale, Sachin B. Patkar, International Conference on High Performance Computing (HiPC), 2009* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5433184)] ![](https://img.shields.io/badge/HiPC2009-orange)
- **A parallel computing method using blocked format with optimal partitioning for SpMV on GPU**. *Wangdong Yang, Kenli Li, Keqin Li ,Journal of Computer and System Sciences (JCSS), 2018* [[DOI](https://www.sciencedirect.com/science/article/pii/S0022000017301587)] ![](https://img.shields.io/badge/JCSS2018-orange)
- **Adaptive Multi-Level Blocking Optimization for Sparse Matrix Vector Multiplication on GPU**. *Yusuke Nagasaka, Akira Nukada, Satoshi Matsuoka, Procedia Computer Science (Procedia Comput. Sci), 2016* [[DOI](https://dl.acm.org/doi/10.1016/j.procs.2016.05.304)]
- **Sparse Matrix Solvers on the GPU: Conjugate Gradients and Multigrid**. *Jeff Bolz, Ian Farmer, Eitan Grinspun,  Peter Schr¨ oder, ACM Transactions on Graphics (TOG), 2003* [[pdf](https://www.cs.columbia.edu/cg/pdfs/28_GPUSim.pdf)] ![](https://img.shields.io/badge/TOG2003-orange)
- **Optimization of Quasi-Diagonal Matrix-Vector Multiplication on GPU**. *Wangdong Yang, Kenli Li, Yan Liu, Lin Shi, Lanjun Wan, International Journal of High Performance Computing Applications (Int J High Perform Comput Appl), 2014* [[DOI](https://dl.acm.org/doi/10.1177/1094342013501126)]
- **TaiChi: A Hybrid Compression Format for Binary Sparse Matrix-Vector Multiplication on GPU**. *Jianhua Gao, Weixing Ji, Zhaonian Tan, Yizhuo Wang, Feng Shi, IEEE Transactions on Parallel and Distributed Systems (IEEE Trans Parallel Distrib Syst), 2022* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9763312)] [[code](https://github.com/BIT-SYS/iSparse/tree/main/BinarySpMV/TaiChi)]
- **Optimizing and auto-tuning scale-free sparse matrix-vector multiplication on Intel Xeon Phi**. *Wai Teng Tang, Ruizhe Zhao, Mian Lu, Yun Liang, Huynh Phung Huyng, Xibai Li, International Symposium on Code Generation and Optimization (CGO), 2015* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7054194)] ![](https://img.shields.io/badge/CGO2015-orange)
- **Implementing Blocked Sparse Matrix-Vector Multiplication on NVIDIA GPUs**. *Alexander Monakov, Arutyun Avetisyan, Embedded Computer Systems: Architectures, Modeling, and Simulation (SAMOS), 2009* [[DOI](https://link.springer.com/chapter/10.1007/978-3-642-03138-0_32)] ![](https://img.shields.io/badge/SAMOS2009-orange)
- **MMSparse: 2D partitioning of sparse matrix based on mathematical morphology**. *Zhaonian Tan, Weixing Ji, Jianhua Gao, Yueyan Zhao, Akrem Benatia, Yizhuo Wang, Feng Shi, Future Generation Computer Systems (Future Gener Comput Syst), 2020 [[DOI](https://www.sciencedirect.com/science/article/abs/pii/S0167739X19327967)] [[code](https://double-flower.github.io/publication/2020-07-01-paper-MMSparse)]
- **TileSpMV: A Tiled Algorithm for Sparse Matrix-Vector Multiplication on GPUs**. *Yuyao Niu, Zhengyang Lu, Meichen Dong, Zhou Jin, Weifeng Liu, Guangming Tan, International Symposium on Parallel and Distributed Processing (IPDPS), 2021* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9460505)] ![](https://img.shields.io/badge/IPDPS2021-orange)

#### Other variants
- **Optimizing Sparse Matrix-Vector Product Computations Using Unroll and Jam**. *John Mellor-Crummey, John Garvin, International Journal of High Performance Computing Applications (Int J High Perform Comput Appl), 2004* [[pdf](https://www.cs.rice.edu/~johnmc/papers/sparse-ijhpca04.pdf)]
- **Anewapproachfor sparse matrix vector product on NVIDIAGPUs**. *Francisco Vázquez, José-Jesús Fernández, Ester M. Garzón, Concurrency Computation Practice and Experience (Concurr Comput),2011* [[pdf](http://www.hpca.ual.es/~fvazquez/fp-content/attachs/spmvcpe.pdf)]
- **Parallel solution of linear systems with striped sparse matrices**. *Rami Melhem, Parallel Computing (Parallel Comput), 1988* [[DOI](https://www.sciencedirect.com/science/article/abs/pii/0167819188900828)]
- **An optimal storage format for sparse matrices**. *Eurı́pides Montagne, Anand Ekambaram, Information Processing Letters (Inf Process Lett), 2004* [[DOI](https://www.sciencedirect.com/science/article/abs/pii/S0020019004000249)]

## Auto-Tuning Based Algorithm

### Offline Auto-Tuning
- **Optimizing Sparse Matrix Computations for Register Reuse in SPARSITY**. *Eun-Jin Im, Katherine Yelick, Proceedings of the International Conference on Computational Sciences-Part I (ICCS), 2001* [[pdf](https://link.springer.com/content/pdf/10.1007/3-540-45545-0_22.pdf)] ![](https://img.shields.io/badge/ICCS2001-orange)
- **SPARSITY: Optimization Framework for Sparse Matrix Kernels**. *Eun-Jin Im, Katherine Yelick, Richard Vuduc, International Journal of High Performance Computing Applications (Int J High Perform Comput Appl), 2004* [[pdf](http://bebop.cs.berkeley.edu/pubs/im2004-sparsity.pdf)]
- **Performance Optimizations and Bounds for Sparse Matrix-Vector Multiply**. *Rich Vuduc, James Demmel, Katherine A. Yelick, Shoaib Kamil, Rajesh Nishtala, Benjamin C. Lee, Supercomputing Conference (SC), 2002* [[DOI](https://ieeexplore.ieee.org/document/1592862)] ![](https://img.shields.io/badge/SC2002-orange)
- **Automatic Performance Tuning of Sparse Matrix Kernels**. *Richard Wilson Vuduc,  A dissertation submitted for the degree of
 Doctor of Philosophy, 2003* [[pdf](https://bebop.cs.berkeley.edu/pubs/vuduc2003-dissertation.pdf)] ![](https://img.shields.io/badge/arXiv2003-orange)
- **OSKI: A Library of Automatically Tuned Sparse Matrix Kernels**. *Richard Vuduc, James W Demmel and Katherine A Yelick, SCIENTIFIC DISCOVERY THROUGH ADVANCED COMPUTING (SciDAC), 2005* [[pdf](https://bebop.cs.berkeley.edu/pubs/jop2005-SciDAC-OSKI.pdf)] ![](https://img.shields.io/badge/SciDAC2005-orange)
- **When cache blocking of sparse matrix vector multiply works and why**. *Rajesh Nishtala, Richard W. Vuduc, James W. Demmel, Katherine A. Yelick, Applicable Algebra in Engineering, Communication and Computing (Appl. Algebra Eng. Commun. Comput), 2007* [[pdf](https://bebop.cs.berkeley.edu/pubs/nishtala2007-cb-spmv.pdf)]
- **Automatic Performance Tuning of SpMV on GPGPU**. *Xianyi Zhang, Yunquan Zhang, Xiangzheng Sun, Fangfang Liu, Shengfei Liu, Yuxin Tang, Yucheng Li, Computer Systems Science and Engineering (Comput. Syst. Sci. Eng.), 2009* [[pdf](https://xianyi.github.io/paper/GOSpMV_2009.pdf)]
- **Model-driven autotuning of sparse matrix-vector multiply on GPUs**. *JeeWhan Choi, Amik Singh, Richard W. Vuduc, ACM SIGPLAN Notices (ACM SIGPLAN Not), 2010* [[pdf](https://vuduc.org/pubs/choi2010-gpu-spmv.pdf)] ![](https://img.shields.io/badge/ACMSIGPLANNot2010-orange)
- **A Performance Modeling and Optimization Analysis Tool for Sparse Matrix-Vector Multiplication on GPUs**. *Ping Guo, Liqiang Wang, Po Chen, IEEE Transactions on Parallel and Distributed Systems (IEEE Trans Parallel Distrib Syst), 2014* [[pdf](https://www.cs.ucf.edu/~lwang/papers/TPDS-2013.pdf)]
- **Performance Analysis and Optimization for SpMV on GPU Using Probabilistic Modeling**. *Kenli Li, Wangdong Yang, Keqin Li, IEEE Transactions on Parallel and Distributed Systems (IEEE Trans Parallel Distrib Syst), 2015* [[pdf](http://www.cs.newpaltz.edu/~lik/publications/Wangdong-Yang-IEEE-TPDS-2015.pdf)]
- **Automatic Tuning of the Sparse Matrix Vector Product on GPUs Based on the ELLR-T Approach**. *Francisco Vázquez, José Jesús Fernández, Ester M. Garzón, Parallel Computing (Parallel Comput.), 2012* [[pdf](http://www.hpca.ual.es/~fvazquez/fp-content/attachs/ParCo2011.pdf)]
- **Improving the Performance of the Sparse Matrix Vector Product with GPUs**. *Francisco V´azquez, Gloria Ortega, José Jesús Fernández, Ester M. Garzón, IEEE International Conference on Computer and Information Technology (CIT), 2010* [[pdf](https://www.researchgate.net/publication/221193414_Improving_the_Performance_of_the_Sparse_Matrix_Vector_Product_with_GPUs)] ![](https://img.shields.io/badge/CIT2010-orange)
- **Automatic tuning of sparse matrix-vector multiplication on multicore clusters**. *ShiGang Li, ChangJun Hu, JunChao Zhang, YunQuan Zhang, Science China Information Sciences (Sci. China Inf. Sci), 2015* [[DOI](https://link.springer.com/article/10.1007/s11432-014-5254-x)] 
- **hpSpMV: A Heterogeneous Parallel Computing Scheme for SpMV on the Sunway TaihuLight Supercomputer**. *Yuedan Chen, Guoqing Xiao, Zheng Xiao, Wangdong Yang, IEEE International Conference on High Performance Computing and Communications (HPCC), 2019* [[DOI](https://ieeexplore.ieee.org/document/8855593)] ![](https://img.shields.io/badge/HPCC2019-orange)
  
### Online Auto-Tuning
- **Auto-Tuning CUDA Parameters for Sparse Matrix-Vector Multiplication on GPUs**. *Ping Guo, Liqiang Wang, International Conference on Computational and Information Sciences (ICCIS), 2010* [[pdf](https://www.cs.ucf.edu/~lwang/papers/ICCIS2010.pdf)] ![](https://img.shields.io/badge/ICCIS2010-orange)
- **Efficient sparse matrix-vector multiplication on cache-based GPUs**. *István R eguly, Mike Giles, Innovative Parallel Computing (InPar), 2012* [[pdf](https://people.maths.ox.ac.uk/~gilesm/files/InPar_spMV.pdf)] ![](https://img.shields.io/badge/InPar2012-orange)
- **Auto-tuning of Sparse Matrix-Vector Multiplication on Graphics Processors**. *Walid Abu-Sufah, Asma Abdel Karim, Supercomputing
(ISC), 2013* [[pdf](https://link.springer.com/chapter/10.1007/978-3-642-38750-0_12)] ![](https://img.shields.io/badge/ISC2013-orange)
- **An Effective Approach for Implementing Sparse Matrix-Vector Multiplication on Graphics Processing Units**. *Walid Abu-Sufah, Asma Abdel Karim, IEEE International Conference on High Performance Computing and Communications (HPCC), 2012* [[pdf](https://www.researchgate.net/publication/268800600_On_Implementing_Sparse_Matrix_Multi-Vector_Multiplication_on_GPUs)] ![](https://img.shields.io/badge/PHCC2012-orange)
- **CRSD: Application Specific Auto-tuning of SpMV for Diagonal Sparse Matrices**. *Xiangzheng Sun, Yunquan Zhang, Ting Wang, Guoping Long, Xianyi Zhang, Yan Li, Euro-Par 2011 Parallel Processing (Euro-Par), 2011* [[pdf](https://link.springer.com/content/pdf/10.1007/978-3-642-23397-5_32.pdf?pdf=inline%20link)] ![](https://img.shields.io/badge/EuroPar2011-orange)
- **yaSpMV: Yet Another SpMV Framework on GPUs**. *Shengen Yan, Chao Li, Yunquan Zhang, Huiyang Zhou, ACM SIGPLAN Notices (ACM SIGPLAN Not), 2014* [[pdf](https://hzhou.wordpress.ncsu.edu/files/2022/12/ppopp_14_2.pdf)] ![](https://img.shields.io/badge/ACMSIGPLANNot2014-orange) 

## Machine-Learning Based Algorithm
### Format or Algorithm Selection
- **Reinforcement Learning for Automated Performance Tuning: Initial Evaluation for Sparse Matrix Format Selection**. *Warren Armstrong, Alistair P. Rendell, IEEE International Conference on Cluster Computing (CLUSTER),2008* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4663802)] ![](https://img.shields.io/badge/CLUSTER2008-orange)
- **SMAT: An Input Adaptive Auto-Tuner for Sparse Matrix-Vector Multiplication**. *Jiajia Li, Guangming Tan, Mingyu Chen, Ninghui Sun, ACM SIGPLAN Notices (ACM SIGPLAN Not), 2013* [[DOI](https://dl.acm.org/doi/10.1145/2499370.2462181)] ![](https://img.shields.io/badge/ACMSIGPLANNot2013-orange)
- **Automatic Selection of Sparse Matrix Representation on GPUs**. *Naser Sedaghati, Te Mu, Louis-Noel Pouchet, Srinivasan Parthasarathy, P. Sadayappan, Proceedings of the 29th ACM on International Conference on Supercomputing (ICS), 2015* [[pdf](https://www.cs.colostate.edu/~pouchet/doc/ics-article.15b.pdf)] ![](https://img.shields.io/badge/ICS2015-orange)
- **Adaptive Optimization of Sparse Matrix-Vector Multiplication on Emerging Many-Core Architectures**. *Shizhao Chen, Jianbin Fang, Donglin Chen, Chuanfu Xu, Zheng Wang, IEEE International Conference on High Performance Computing and Communications (HPCC), 2018* [[pdf](https://jianbinfang.github.io/files/2018-06-28-aspmv.pdf)] ![](https://img.shields.io/badge/HPCC2018-orange)
- **Sparse Matrix Format Selection with Multiclass SVM for SpMV on GPU**. *Akrem Benatia, Weixing Ji, Yizhuo Wang, Feng Shi, International Conference on Parallel Processing (ICPP), 2016* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7573853)] ![](https://img.shields.io/badge/ICPP2016-orange)
- **Machine Learning for Optimal Compression Format Prediction on Multiprocessor Platform**. *Ichrak Mehrez, Olfa Hamdi-Larbi, Thomas Dufaud, Nahid Emad, International Conference on High Performance Computing & Simulation (HPCS), 2018* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8514352)] ![](https://img.shields.io/badge/HPCS2018-orange)
- **Auto-Tuning Strategies for Parallelizing Sparse Matrix-Vector (SpMV) Multiplication on Multi- and Many-Core Processors**. *Kaixi Hou, Wu-chun Feng, Shuai Che, IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum (IPDPSW), 2017* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7965113)] ![](https://img.shields.io/badge/IPDPSW2017-orange)
- **BestSF: A Sparse Meta-Format for Optimizing SpMV on GPU**. *Akrem Benatia, Weixing Ji, Yizhuo Wang, Feng Shi, ACM Transactions on Architecture and Code Optimization (TACO), 2018* [[pdf](https://dl.acm.org/doi/pdf/10.1145/3226228)] [[code](https://github.com/sparse-bit/bestsf)] ![](https://img.shields.io/badge/TACO2018-orange)
- **Effective Machine Learning Based Format Selection and Performance Modeling for SpMV on GPUs**. *Israt Nisa, Charles Siegel, Aravind Sukumaran Rajam, Abhinav Vishnu, P. Sadayappan, IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum (IPDPSW), 2018* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8425531)] ![](https://img.shields.io/badge/IPDPSW2018-orange)
- **A Machine Learning-Based Approach for Selecting SpMV Kernels and Matrix Storage Formats**. *Hang CUI, Shoichi Hirasawa, Hiroaki Kobayashi, Hiroyuki Takizawa, IEICE Transactions on Information and Systems (IEICE Trans Inf Syst), 2018* [[pdf](https://www.jstage.jst.go.jp/article/transinf/E101.D/9/E101.D_2017EDP7176/_pdf)]
- **Bridging the Gap Between Deep Learning and Sparse Matrix Format Selection**. *Yue Zhao, Jiajia Li, Chunhua Liao, Xipeng Shen, Proceedings of the 23rd ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming(PPoPP), 2018* [[pdf](https://dl.acm.org/doi/pdf/10.1145/3178487.3178495)] ![](https://img.shields.io/badge/PPoPP2018-orange)
- **Machine Learning to Design an Auto-tuning System for the Best Compressed Format Detection for Parallel Sparse Computations**. *Olfa Hamdi-Larbi, Ichrak Mehrez, Thomas Dufaud, Parallel Processing Letters (Parallel Process Lett), 2021* [[DOI](https://worldscientific.com/doi/abs/10.1142/S0129626421500195)]
- **Enabling Runtime SpMV Format Selection through an Overhead Conscious Method**. *Weijie Zhou, Yue Zhao, Xipeng Shen, Wang Chen, IEEE Transactions on Parallel and Distributed Systems (IEEE Trans Parallel Distrib Syst) [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8787872)]
- **BASMAT: Bottleneck-Aware Sparse Matrix-Vector Multiplication Auto-Tuning on GPGPUs**. *Athena Elafrou, Georgios Goumas, Nectarios Koziris, Proceedings of the 24th Symposium on Principles and Practice of Parallel Programming (PPoPP), 2019* [[DOI](https://dl.acm.org/doi/abs/10.1145/3293883.3301490)] ![](https://img.shields.io/badge/PPoPP2019-orange)
- **Selecting Optimal SpMV Realizations for GPUs via Machine Learning**. *Ernesto Dufrechou1, Pablo Ezzatti, Enrique S Quintana-Ort´ı, The international journal of high performance computing applications (Int J High Perform Comput Appl), 2021* [[pdf](https://riunet.upv.es/bitstream/handle/10251/184043/DufrechouEzzattiQuintana-Orti%20-%20Selecting%20optimal%20SpMV%20realizations%20for%20GPUs%20via%20machine%20learning.pdf;jsessionid=B821E9DAE9E8379B34495F66025C25B4?sequence=1)][[code](https://cusplibrary.github.io/)] [[code](https://ginkgo-project.github.io/)] [[code](https://github.com/weifengliu-ssslab/Benchmark_SpMV_using_CSR)] [[code](https://github.com/poojahira/spmv-cuda)]
- **DTSpMV: An Adaptive SpMV Framework for Graph Analysis on GPUs**. *Guoqing Xiao, Tao Zhou, Yuedan Chen, Yikun Hu, Kenli Li, IEEE International Conference on High Performance Computing and Communications (HPCC), 2022* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10074875)] ![](https://img.shields.io/badge/HPCC2022-orange)
 
### Parameter Prediction
- **Auto-Tuning Strategies for Parallelizing Sparse Matrix-Vector (SpMV) Multiplication on Multi- and Many-Core Processors**. *Kaixi Hou, Wu-chun Feng, Shuai Che, IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum (IPDPSW), 2017* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7965113)] ![](https://img.shields.io/badge/IPDPSW2017-orange)
- **ZAKI: A smart method and tool for automatic performance optimization of parallel SpMV computations on distributed memory machines**. *Sardar Usman, Rashid Mehmood, Iyad Katib, Aiiad Albeshri, Saleh M. Altowaijri, Mobile Networks and Applications (Mob. Netw. Appl), 2019* [[DOI](https://link.springer.com/article/10.1007/s11036-019-01318-3)]
- **ZAKI+: A Machine Learning Based Process Mapping Tool for SpMV Computations on Distributed Memory Architectures**. *Sardar Usman, Rashid Mehmood, Iyad Katib, Aiiad Albeshri, IEEE Access, 2019* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8737900)] ![](https://img.shields.io/badge/IEEEAccess2019-orange)
- **AAQAL: A Machine Learning-Based Tool for Performance Optimization of Parallel SpMV Computations Using Block CSR**. *Muhammad Ahmed, Sardar Usman, Nehad Ali Shah, M. Usman Ashraf, Ahmed Mohammed Alghamdi, Adel A. Bahadded, Khalid Ali Almarhabi, Applied Sciences (Appl. Sci), 2022* [[DOI](https://www.mdpi.com/2076-3417/12/14/7073)]
- **Revisiting thread configuration of SpMV kernels on GPU: A machine learning based approach**. *Jianhua Gao, Weixing Ji, Jie Liu, Yizhuo Wang, Feng Shi, Journal of Parallel and Distributed Computing (J Parallel Distrib Comput), 2024* [[DOI](https://www.sciencedirect.com/science/article/abs/pii/S0743731523001697)]

### Performance Prediction
- **Machine Learning Approach for the Predicting Performance of SpMV on GPU**. *Akrem Benatia, Weixing Ji, Yizhuo Wang, Feng Shi, International Conference on Parallel and Distributed Systems (ICPADS), 2016* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7823835)] ![](https://img.shields.io/badge/ICPADS2016-orange)
- **Sparse matrix partitioning for optimizing SpMV on CPU-GPU heterogeneous platforms**. *Akrem Benatia, Weixing Ji, Yizhuo Wang, Feng Shi, The International Journal of High Performance Computing Applications (Int J High Perform Comput Appl), 2019* [[DOI](https://journals.sagepub.com/doi/abs/10.1177/1094342019886628?journalCode=hpcc)]
- **Effective Machine Learning Based Format Selection and Performance Modeling for SpMV on GPUs**. *Israt Nisa, Charles Siegel, Aravind Sukumaran Rajam, Abhinav Vishnu, P. Sadayappan, IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW), 2018* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8425531)] ![](https://img.shields.io/badge/IPDPSW2018-orange)
- **Performance Modeling of the Sparse Matrix-Vector Product via Convolutional Neural Networks**. *Maria Barreda, Manuel F. Dolz, M. Asunción Castaño, Pedro Alonso-Jordá, Enrique S. Quintana-Ortí, The Journal of Supercomputing (J SUPERCOMPUT), 2020* [[DOI](https://link.springer.com/article/10.1007/s11227-020-03186-1)]
- **Convolutional Neural Nets for Estimating the Run Time and Energy Consumption of the Sparse Matrix-Vector Product**. *Maria Barreda, Manuel F Dolz, M Asunción Castaño, The International Journal of High Performance Computing Applications (Int J High Perform Comput Appl), 2021* [[DOI](https://journals.sagepub.com/doi/10.1177/1094342020953196)] 

## Mixed Precision Based Optimization

### Mixed-Precision SpMV
- **Exploiting variable precision in GMRES**. *Serge Gratton, Ehouarn Simon, David Titley-Peloquin, Philippe Toint, arXiv, 2019* [[pdf](https://arxiv.org/pdf/1907.10550)] ![](https://img.shields.io/badge/Arxiv2019-orange)
- **Compressed basis {GMRES} on high-performance graphics processing units**. *José I Aliaga, Hartwig Anzt, Thomas Grützmacher, Enrique S. Quintana-Ortí, Andrés E. Tomás, The International Journal of High Performance Computing Applications (Int J High Perform Comput Appl), 2023* [[DOI](https://journals.sagepub.com/doi/full/10.1177/10943420221115140)]
- **Improving the Performance of the GMRES Method Using Mixed-Precision Techniques**. *Neil Lindquist, Piotr Luszczek, Jack Dongarra, Driving Scientific and Engineering Discoveries Through the Convergence of HPC, Big Data and AI (SMC), 2020* [[DOI](https://link.springer.com/chapter/10.1007/978-3-030-63393-6_4)]
- **A study of mixed precision strategies for GMRES on GPUs**. *Jennifer A. Loe, Christian A. Glusa, Ichitaro Yamazaki, Erik G. Boman, Sivasankaran Rajamanickam, arXiv, 2021* [[pdf](https://arxiv.org/pdf/2109.01232)] ![](https://img.shields.io/badge/Arxiv2021-orange)
- **Accelerating the Solution of Linear Systems by Iterative Refinement in Three Precisions**. *Authors: Erin Carson, Nicholas J. Higham, SIAM Journal on Scientific Computing (SIAM J. Sci. Comput), 2018* [[pdf](https://epubs.siam.org/doi/epdf/10.1137/17M1140819)] [[code](https://github.com/eccarson/ir3)]
- **Mixed-precision in-memory computing**. *Manuel Le Gallo, Abu Sebastian, Roland Mathis, Matteo Manica, Heiner Giefers, Tomas Tuma, Costas Bekas, Alessandro Curioni, Evangelos Eleftheriou, Nature Electronics (Nat. Electron), 2018* [[DOI](https://www.nature.com/articles/s41928-018-0054-8)]

### Mixed-Precision SpMV
- **Data-driven Mixed Precision Sparse Matrix Vector Multiplication for GPUs**. *Khalid Ahmad, Hari Sundar, Mary Hall, ACM Transactions on Architecture and Code Optimization (TACO), 2020* [[pdf](https://dl.acm.org/doi/pdf/10.1145/3371275)] ![](https://img.shields.io/badge/TACO2020-orange)
- **Performance and energy consumption of accurate and mixed-precision linear algebra kernels on GPUs**. *Daichi Mukunoki, Takeshi Ogita, Journal of Computational and Applied Mathematics (J. Comput. Appl. Math), 2020* [[DOI](https://www.sciencedirect.com/science/article/pii/S037704271930706X)]
- **Mixed and Multi-Precision SpMV for GPUs with Row-wise Precision Selection**. *Erhan Tezcan, Tugba Torun, Fahrican Koşar, Kamer Kaya, Didem Unat, International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD), 2022* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9980904)]
- **Adaptive precision matrix-vector product**. *Stef Graillat, Fabienne Jézéquel, Théo Mary, Roméo Molina, HAL, 2022* [[pdf](https://hal.science/hal-03561193v1/file/rapport.pdf)] ![](https://img.shields.io/badge/Arxiv2022-orange)
- **Multiple-precision sparse matrix-vector multiplication on GPUs**. *Konstantin Isupov, Journal of Computational Science (J Comput Sci), 2022* [[DOI](https://www.sciencedirect.com/science/article/abs/pii/S1877750322000382)]
- **A Highly Efficient Implementation of Multiple Precision Sparse Matrix-Vector Multiplication and Its Application to Product-type Krylov Subspace Methods**. *Tomonori Kouya, arXiv, 2014* [[pdf](https://arxiv.org/pdf/1411.2377)] ![](https://img.shields.io/badge/Arxiv2014-orange)

## Architecture Oriented Optimization
### CPU
- **Performance of a Structure-Detecting SpMV Using the CSR Matrix Representation**. *Hans Pabst, Bev Bachmayer, Michael Klemm, International Symposium on Parallel and Distributed Computing (HPDC), 2012* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6341487)] ![](https://img.shields.io/badge/HPDC2012-orange)
- **CSR5: An Efficient Storage Format for Cross-Platform Sparse Matrix-Vector Multiplication**. *Weifeng Liu, Brian Vinter, Proceedings of the 29th ACM on International Conference on Supercomputing (ICS), 2015*[[DOI]([https://arxiv.org/pdf/1503.05032](https://dl.acm.org/doi/10.1145/2751205.2751209))] [[code](https://github.com/weifengliu-ssslab/Benchmark_SpMV_using_CSR5)] ![](https://img.shields.io/badge/ICS2015-orange)
- **CSR2: A New Format for SIMD-Accelerated SpMV**. *Haodong Bian, Jianqiang Huang, Runting Dong, Lingbin Liu, Xiaoying Wang, IEEE/ACM International Symposium on Cluster Computing and the Grid (CCGRID), 2020* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9139720)] [[code](https://github.com/nulidangxueshen/CSR2)] ![](https://img.shields.io/badge/CCGRID2020-orange)
- **Performance analysis and optimization for SpMV based on aligned storage formats on an ARM processor**. *Yufeng Zhang, Wangdong Yang, Kenli Li, Dahai Tang, Keqin Li, Journal of Parallel and Distributed Computing (J Parallel Distrib Comput), 2021* [[pdf](https://pdf.sciencedirectassets.com/272438/1-s2.0-S0743731521X00093/1-s2.0-S0743731521001684/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEO%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJIMEYCIQDadh8Gmsl%2FANAAIovqGhsr0tJef%2FWzvtCqVK%2F1YChxnAIhAIWnOvbbCeCSr9uuHHqPrFHR%2BB3roJSwopEM1nrMAFI4KrsFCNj%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBRoMMDU5MDAzNTQ2ODY1Igwti7PO7UTygd2mNVwqjwXKYzx323oGyqrH2KTb7EcXLhChvyOTDvuePuYYGR59rPbZ2038kJzicKtdQWVukrlMu2QR68LaENntwuYj41UY6F%2FHZpoCRh52yt8cwhSR2TlUpDgvXtYbDyypeSqqofbTa%2FQhlfAJF7dUHRMW0W3KIPB4h7DskitQ53e7o0C9Pqv92DSPbBzcc6QcO%2BxK7iSkm8rBQuBNKSa4Rm5q48dUJ44rOx4q4P5ooGGz6SduK2Afp8mayPmLOFWlJwkfFD3%2BcUZ0Tx3CTm8Qi8E6MFiUH5I%2FZdMUQuSaFKcZvmVq0Kl%2B9wx34bcK1A5PVImUY20rrb1%2BVK7vKsdy8ZUXJAgcBkholeOAiHGXHCylrHLlwd7lVTmW5NrMxEl9RG6ZNUmm%2FP2mwmY1n28pJ%2FH6bsHJmOxw%2BcEmzzEAXI%2F8yOWGFxGZGZJEyjPTm%2BQS7PSDykSS816dlzH2mgwr%2BEwmaPu9kzwX34gvh%2BMKF4tyoQ3o4uGnEExMEIsNRB8A5d7EV%2FoalHwuxtNf5qMZ8lmvJZp9MZ8GnhVlT4bkigGnw3EDOCb35N2e6rwYvX%2FZeLQBN%2FrhL1FPdyaZM5arwWddRz5uPFf74LMJxrhXsEyMF%2FpysAjymzaUWXdp4ieNiRq2HdnF18wDMO5bZQwMzS2YML3J7iiyLUfx6sinxn57jxgYybqG9Npr6OUr2YobE1vYtmEefj8gYAsH4Ukaf1sIhQ3AY52UgwcZEiYo1%2F4EPFnsCTFQmcIjMDMIZM74LpzcSMtLzaDsLwHll9wPACqjxWJB3SEk2IOLIDTvFg%2F1oaJvj01FXplQTo86cqdWL2Fqxr23MHjfuiWCqr5z4GL6v6iTrG4j7JD1SUg6ug0CCxnfMKGgj7wGOrABXxYDKhUuEWNJ0%2Ft%2BGTAisUT41Bhz8IVXicFP%2B%2FbTzg8NcUT%2FzRKgRSnHLHqTNHG1T6n%2FL824DV0yuv9stfgi6kSETYiRdwwlPpWJYJp4wzFABKMEUweXfzRWWN60VqeOSxsG9DK0TWhMJwEroVTQk4EjUQhULv4ubDpjDQzKqVgcDnjmt7p%2Fvf2pv2JMb%2BfMc4Ljovlf5SmSq3QuhOCj3hOxbJH5FTNoARcQytPuGto%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250112T153106Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY3LDPWNIB%2F20250112%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=d11ebea73fa9fd2640f18e071bb75f54886524ec7a113d34c623ebbc41076e01&hash=fa47ac0713fede2622fe24b2f265193e27c169c18bdeba2c704f218fab93be88&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0743731521001684&tid=spdf-0d9e82fa-b588-440a-b75c-c27d54f6401a&sid=26a7a81e1ae7134edf588830a05124f237b6gxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=0a0e58555203525655&rr=900e3108ef9d6e52&cc=hk&kca=eyJrZXkiOiIrRXVoeXFwbldWbE9EcVZoV09JSUdmcmQxdFFrdDBYVmkwaDJBbm0rbGJKd2E0L0ZlM25zSEZFNnNLazk1a2ZLck5MaXlhaWU0dFBYeGtVMER1YnQ3Z0RlVytWUm5RNmtaM0lIZkFVcjRpOTcvQTRsZVNTbDZ1YmtkTzlQMFRpMFEvU2xwc2dmaE9IOFNGUnNnR2ZQMUZwMVFCL2ZNUTF6ZW1ibHdtQUt5NTR2K04wPSIsIml2IjoiYmIwNzAzNDlhMTY0MmVlMmIyZmY0N2EwYWZiMTQyMDIifQ==_1736695876682)]
- **Sparsity: Optimization Framework for Sparse Matrix Kernels**. *Eun-Jin Im, Katherine Yelick, Richard Vuduc, International Journal of High Performance Computing Applications (Int J High Perform Comput Appl), 2004* [[DOI](https://dl.acm.org/doi/abs/10.1177/1094342004041296)]
- **When cache blocking of sparse matrix vector multiply works and why**. *Rajesh Nishtala, Richard W. Vuduc, James W. Demmel, Katherine A. Yelick, Applicable Algebra in Engineering, Communication and Computing (Appl. Algebra Eng. Commun. Comput), 2007* [[DOI](https://link.springer.com/article/10.1007/s00200-007-0038-9)]
- **Optimization of sparse matrix-vector multiplication on emerging multicore platforms**. *Samuel Williams, Leonid Oliker, Richard Vuduc, John Shalf, Katherine Yelick, James Demmel, Supercomputing Conference (SC), 2007* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5348797)] ![](https://img.shields.io/badge/SC2007-orange)
- **Optimization of sparse matrix–vector multiplication on emerging multicore platforms**. *Samuel Williams, Leonid Oliker, Richard Vuduc, John Shalf, Katherine Yelick, James Demmel, Parallel Computing (Parallel Comput), 2009* [[pdf](https://pdf.sciencedirectassets.com/271636/1-s2.0-S0167819109X00049/1-s2.0-S0167819108001403/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEPD%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIGlqfV4SBbn%2BkpkRX3aiCMDn3OD2cAvmLJlBhuRmqEIBAiEA7crGORZZipBOjYSv0wWt5tA5Zr0zOCqjrJJYDkva%2BjoquwUI2f%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDG0cxZn9Qg3wFwKtiSqPBYatAl0AGxzyucxElAmG1SPAovmLwTzOO0SCMbosVQnw0W7BUYDlBhZxc2rilX2hzB68V3CD6y54IHk2ZrIu9mKnAlCA4is9sUh5YxDKUSL%2FckX37poXFHuwZWQEn7tRlvMtEDML9OzSDx7weVgawBecLODP%2B9FDtYyY1WRQ2xB%2B1mMBaH3n3ipJke%2B3hFEJNBxbhh9zRvPtRQ1G%2FujyiLWywbO8ut4Cy3lEIM2zKqdpiBzfKKD6PZ53HKkbZ4NeTGwogth8%2Bx4D8%2F8ozK7aEyDlAcbyeEOWMzETf5CwrRK6BhtLCznu1J5MsCy7pTh2u524bRVYP1Hj19sRdFqAQXjgloTIYAoNPgnL6g3%2BDBwaUBQASj5zGjJOhka5x9tGoBIfeIWY28bpJsS4j5RQhZ2Av7jdgIJbhS69nYBts48wfWUdzfrbU5e00oKhgC9URgnI0QMB09WkUpnulrH%2BpDaq1eDyLlN1PoMUreO2NfbBr1tw%2BtZEbAqzfmdAuxHq4yiJCpZG8imL9j7Uz5gsu0896SEXgp5gq9YmTm1qP1RpCgezTiffK6aod%2B01QmsjXhhX5XKVnKb03E6cjJswHiqSsiyhFCcTgjv6WTEyhPf5Axo4MJJBkghKl%2FSMB38%2FTxIZrZUGvVsnmV0dZ%2FW%2Bs95P0qtzc6Nn7%2Fx9FNYDu29P3iMGRfjxen9b7trzFlJWflK1bEAqC4jXW6LoYh9nzHD6BdtezwH34EJpCw02qfEDENj%2BeZ8aOjrN0%2BHSjxNmWWyytP4YOmysQSM%2FFD7oJST4gAZGa%2B97S3lCiXD9c2JrLeYoCt9AHIShMbOuH2ZjY07gacdFqNwCE3kNo5SP7YYRzG%2FKe%2Fm1z%2FohYRhNntkwl8CPvAY6sQGDicnKaF78QxocERy5ID9H8q8t%2BzJmHkY7mQyZObpAPMmWhasgNUuNDmlmQnAJBLNhjTavgErsGszcChxnyXjznqZhGI3tgkSxXt2y0sytikpVnkzo5YL8VI3PGR6mPopmNJFMhgDTOX5iXF%2BkEKFJSCkTvMW%2Bf6jzMCQC0wDd4dRboKv2gqr8GRiT2tHVLUfciec%2Fc9fjumf43GijXvDAqHFvUOoN9ORARvMSI01LMQc%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250112T155321Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYXPJZESYE%2F20250112%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=d84d9ae7df473dd71c5499033fc234dcc5a0364e25d357ddab73c6b1965e7568&hash=45fec88c97b1ae9e8eed01b340d848335765d5fe4caf28944304a5002bea864d&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0167819108001403&tid=spdf-11661892-7cd7-40dd-a0f1-a110789af284&sid=26a7a81e1ae7134edf588830a05124f237b6gxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=0a0e58555203545604&rr=900e51a4fec25e00&cc=hk&kca=eyJrZXkiOiIxM1g2YThEQURreUwwcG9qSzZOMkV3OUh0Vm9Dd2s5SlJodUkyL0daMXZSY2FhM1hOa09qR2FPQzRadzNLZ1dOSjdadHpydFQvb2diZmc2RzJmcnp0dWFxdVdTOHFxN2V0NkE5bjg4QStNZW12eVpFeGhhNU81MUp3Q204RDVraXZIV3pLT1VaV2xiamtGdDJ3RVlqSTNPRHlLU0piQ053ZWV5VzN2UitKUnJYSEhnPSIsIml2IjoiYmY4MjU1ODBjMTcyZDY2MTk3YmYxYmZmNGY4Y2YxYTkifQ==_1736697208911)]
- **Optimizing sparse matrix vector multiplication on emerging multicores**. *Orhan Kislal, Wei Ding, Mahmut Kandemir, Ilteris Demirkiran, IEEE International Workshop on Multi-/Many-core Computing Systems (MuCoCoS), 2013* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6633600)] ![](https://img.shields.io/badge/MuCoCoS2013-orange)
- **Memory Access Complexity Analysis of SpMV in RAM (h) Model**. *E. Yuan, Yun-quan Zhang, Xiangzheng Sun, IEEE International Conference on High Performance Computing and Communications (HPCC)， 2008* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4637803)] ![](https://img.shields.io/badge/HPCC2008-orange)
- **Performance Optimizations and Bounds for Sparse Symmetric Matrix- Multiple Vector Multiply**. *Benjamin C. Lee, Katherine A. Yelick, Richard W. Vuduc, James W. Demmel, Michael de Lorimier, Lijue Zhong, Supercomputing Conference (SC), 2003* [[pdf](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2003/CSD-03-1297.pdf)] ![](https://img.shields.io/badge/SCS2003-orange)
- **Performance Evaluation of Multithreaded Sparse Matrix-Vector Multiplication Using OpenMP**. *Shengfei Liu, Yunquan Zhang, Xiangzheng Sun, RongRong Qiu, IEEE International Conference on High Performance Computing and Communications (HPCC), 2009* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5167060)] ![](https://img.shields.io/badge/HPCC2009-orange)
- **Performance Analysis and Optimization of Sparse Matrix-Vector Multiplication on Modern Multi- and Many-Core Processors**. *Athena Elafrou, Georgios Goumas, Nectarios Koziris, International Conference on Parallel Processing (ICPP), 2017* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8025303)] ![](https://img.shields.io/badge/ICPP2017-orange)
- **Bringing Order to Sparsity: A Sparse Matrix Reordering Study on Multicore CPUs**. *James D. Trotter, Sinan Ekmekçibaşi, Johannes Langguth, Tugba Torun, Emre Düzakın, Aleksandar Ilic, Supercomputing Conference (SC), 2023* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10485109)] ![](https://img.shields.io/badge/SC2023-orange)
- **NUMA-Aware Optimization of Sparse Matrix-Vector Multiplication on ARMv8-Based Many-Core Architectures**. *Xiaosong Yu, Huihui Ma, Zhengyu Qu, Jianbin Fang, Weifeng Liu, Network and Parallel Computing (NPC), 2020* [[pdf](https://www.ssslab.cn/assets/papers/2020-yu-numa.pdf)] ![](https://img.shields.io/badge/NPC2020-orange)

### GPU

#### Single GPU
- **Scalable Parallel Programming with CUDA: Is CUDA the parallel programming model that application developers have been waiting for?**. *John Nickolls, Ian Buck, Michael Garland, Kevin Skadron, ACM Queue (Queue), 2008* [[pdf](https://dl.acm.org/doi/pdf/10.1145/1365490.1365500)] ![](https://img.shields.io/badge/Queue2008-orange)
- **Fast Sparse Matrix-Vector Multiplication on GPUs for Graph Applications**. *Arash Ashari, Naser Sedaghati, John Eisenlohr, Srinivasan Parthasarath, P. Sadayappan, Supercomputing Conference (SC), 2014* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7013051)] ![](https://img.shields.io/badge/SC2014-orange)
- **Efficient Sparse Matrix-Vector Multiplication on GPUs Using the CSR Storage Format**. *Joseph L. Greathouse, Mayank Daga, Supercomputing Conference (SC), 2014* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7013050)] ![](https://img.shields.io/badge/SC2014-orange)
- **Structural Agnostic SpMV: Adapting CSR-Adaptive for Irregular Matrices**. *Mayank Daga, Joseph L. Greathouse, International Conference on High Performance Computing (HIPC), 2015* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7397620)] [[code](https://github.com/clMathLibraries/clSPARSE/)] ![](https://img.shields.io/badge/HIPC2015-orange)
- **CSR5: An Efficient Storage Format for Cross-Platform Sparse Matrix-Vector Multiplication**. *Weifeng Liu, Brian Vinter, Proceedings of the 29th ACM on International Conference on Supercomputing (ICS), 2015*[[DOI]([https://arxiv.org/pdf/1503.05032](https://dl.acm.org/doi/10.1145/2751205.2751209))] [[code](https://github.com/weifengliu-ssslab/Benchmark_SpMV_using_CSR5)] ![](https://img.shields.io/badge/ICS2015-orange)
- **Merge-Based Parallel Sparse Matrix-Vector Multiplication**. *Duane Merrill, Michael Garland, Supercomputing Conference (SC), 2016* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7877136)] [[code](https://github.com/dumerrill/merge-spmv)] ![](https://img.shields.io/badge/SC2016-orange)
- **Overcoming Load Imbalance for Irregular Sparse Matrices**. *Goran Flegar, Hartwig Anzt, The International Conference for High Performance Computing, Networking, Storage and Analysis (SC), 2017* [[DOI](https://dl.acm.org/doi/10.1145/3149704.3149767)] ![](https://img.shields.io/badge/SC2017-orange)
- **Load-Balancing Sparse Matrix Vector Product Kernels on GPUs**. *Hartwig Anzt, Terry Cojean, Yen-Chen Chen, Jack Dongarra, Goran Flegar, Pratik Nayak, Stanimire Tomov, Yuhsiang M.Tsai, Weichung Wang, ACM Transactions on Parallel Computing (TOPC), 2020* [[pdf](https://dl.acm.org/doi/pdf/10.1145/3380930)] [[code](https://ginkgo-project.github.io/)][[code](https://github.com/ginkgo-project/ginkgo)] [[code](https://github.com/ginkgo-project/ginkgo-data)] [[code](https://ginkgo-project.github.io/gpe/)] ![](https://img.shields.io/badge/TOPC2020-orange)
- **AMF-CSR: Adaptive Multi-Row Folding of CSR for SpMV on GPU**. *Jianhua Gao, Weixing Ji, Jie Liu, Senhao Shao, Yizhuo Wang, Feng Shi, International Conference on Parallel and Distributed Systems (ICPADS), 2021* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9763779)]
- **Compressed Multirow Storage Format for Sparse Matrices on Graphics Processing Units**. *Zbigniew Koza, Maciej Matyka, Sebastian Szkoda, Łukasz Mirosław, SIAM Journal on Scientific Computing (SIAM J. Sci. Comput), 2014* [[pdf]([https://dl.acm.org/doi/10.1137/120900216](https://typeset.io/pdf/compressed-multirow-storage-format-for-sparse-matrices-on-2vty8nls6b.pdf))]
- **Globally homogeneous, locally adaptive sparse matrix-vector multiplication on the GPU**. *Markus Steinberger, Rhaleb Zayer, Hans-Peter SeidelAuthors Info, Claims, Proceedings of the International Conference on Supercomputing (ICS), 2017* [[pdf](https://markussteinberger.net/papers/GloballyHomogeneousLocallyAdaptiveSparseMatrixVectorMultiplication.pdf)] ![](https://img.shields.io/badge/ICS2017-orange)
- **Optimizing Sparse Matrix-Vector Multiplication on GPUs**. *Muthu Manikandan Baskaran, Rajesh Bordawekar, Computer Science, Engineering (CSE), 2009* [[DOI](https://www.semanticscholar.org/paper/Optimizing-Sparse-Matrix-Vector-Multiplication-on-Baskaran-Bordawekar/cb600c8aca79428fc4812ee7e3eaa960f2cbe448)] ![](https://img.shields.io/badge/CSE2009-orange)
- **Efficient Sparse Matrix-Vector Multiplication on CUDA**. *Nathan Bell, Michael Garland, NVIDIA Technical Report (NVR),2008* [[DOI](https://research.nvidia.com/publication/2008-12_efficient-sparse-matrix-vector-multiplication-cuda)] ![](https://img.shields.io/badge/NVR2008-orange)
- **Implementing sparse matrix-vector multiplication on throughput-oriented processors**. *Nathan Bell, Michael Garland, Supercomputing Conference (SC), 2009* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6375570)] ![](https://img.shields.io/badge/SC2009-orange)
- **Efficient sparse matrix-vector multiplication on cache-based GPUs**. *István R eguly, Mike Giles, Innovative Parallel Computing (InPar), 2012* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6339602)] ![](https://img.shields.io/badge/InPar2012-orange)
- **Automatic Tuning of Sparse Matrix-Vector Multiplication for CRS Format on GPUs**. *Hiroki Yoshizawa, Daisuke Takahashi, IEEE International Conference on Computational Science and Engineering (CSE), 2012* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6417285)] ![](https://img.shields.io/badge/CSE2012-orange)
- **Revisiting thread configuration of SpMV kernels on GPU: A machine learning based approach**. *Jianhua Gao, Weixing Ji, Jie Liu, Yizhuo Wang, Feng Shi, Journal of Parallel and Distributed Computing (J Parallel Distrib Comput), 2024* [[pdf](https://pdf.sciencedirectassets.com/272438/1-s2.0-S0743731523X00124/1-s2.0-S0743731523001697/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEPH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJIMEYCIQC9OctJuNg7CYYbcEKHFMb9M8nNmVgkVOIdh62TC%2F031QIhAPmsr2bHxn%2BB5dqWNoI3mhiJateJ%2FPoQG4J3gi%2Fxiq3KKrsFCNr%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBRoMMDU5MDAzNTQ2ODY1Igwbvt2ywP%2F%2BmDsvsWEqjwUwRaX6dqfarEWd54fZt2URcYidYtEHrjwQpQ4enmA%2FBLEalP2RHhStiFb2TGlaywX176C2xr2e3ggOhhFraKqLIJcZ9MFVr%2BIGF5sSThtP35tWXc0KbLvEc%2F2DOJA5ox%2Bxk%2B1xdoEuqeImLAL6QCrpie4Jnw3corEDAU0wjo1Q5YDZoNDNjheE4vOeuuyabG1gXX0Zn0hpTivWT2NtFZHugUBu6O%2BqiEYJN%2FZh7R1ArEl02pOb65DvNx%2FFNJoowEpqbnXgziA0Vjzx58NCX9qIT0UKJfjIIET73Zj7TnH84PNFPNYobhs7DoalZ49b3%2FhEGcOpnhapxGTOD6u3WFEgH6cKKc%2FJH8AAQby8telwSFjCd60A32BdHhbcpODvj1DhyAf29GPoyHk0ka4153Fwz2BTSiC9GuJlt2pYKbE8dHncMhghQ4%2BajhlxKAmkZQvW2B8i3ZO4%2FoqdJ1rZMVgOiPhS25d1Ls60DN1u6fQqh6FWomeJvQ6ZEjR%2FTwOkauOAmn63UOev7cmhmRFEhO7cUAYO7JqgBbLvmfBXAt%2BASknbgb%2B10ogqefLEe1WVeqoNMzIsAjQcrApLTN4s0BkYcvVYeoDATbSJP6TuKM7hiGslLqVArgKiXlF9t%2BgYHD183Xvxdetd1NaqORAJtTIChW7Z3tD7ky0v6fE2byMpI6lABZdXqADS6sFpsqkZ5sw%2BnMvhtLMYfbPpJRZNZ7zogT%2B4IJoM71WmC4EalZkL7OrJi%2Fn%2BQ5i%2Bevma6JjiBtf8ooa07hb22aBhHTPsX8jNYTBV0rYDdrgJSM3l4%2BqTuwWdxIajyKPa8gGcQ2yH4gnqeftquxYwbHyTpQqi%2BJv%2BdfJ24Ck%2BDEwwSltitdIDMMndj7wGOrABqNAj57fN3XhBIsU95yn19sn5azmKNPvF406W%2FOMeIr2wpHvQ4OE20klFw67Wqe7oymYwDw0ZG%2F1NnZzMm1LdNlFrlcNC6tsfTSrNQcjC2cc%2B9MF5McU2v93Ztd7Rawyo7bCjLinLIqCvx6FoDZyuGzK96Z7u9Qn0J0j6zVA7t12KAOo%2BLyR3vkHRAX0IJlqZIXpLM94gXfZxN%2Fz8BI3fR%2FME7CiVFX3AzeJwIfz0DNs%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250112T174943Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYTBHBDXUJ%2F20250112%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=c6b959dcfa4c1168c03f4fb1386b0b533c9c37d85a528f75571a68ce7124afb4&hash=1ca1a3442f9553d1fd6e5a3ba9071e837e5b4682124d27a7409806a9d9616ab9&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0743731523001697&tid=spdf-1c403913-1469-465e-abd2-600beeb4f8fe&sid=26a7a81e1ae7134edf588830a05124f237b6gxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=0a0e58555203070454&rr=900efc17becd0703&cc=hk&kca=eyJrZXkiOiJYMCtIbGxmQk9KWk9waUUvV2NYdUhVQ1QwNGU4SWNVSlp5a2V5Slk1ZEtkaktMVm93RTBweHBLTEtINnFQVTV3aW5HOWU5OWpMSVJUYVQrOGtzV2NHMlN3cE9lYnBJcDNaditUVmprS2hBQ09hOEVVODU1RGNTZVp3QkNJSXE4cDh4UDZUdXorV3pTRUF3USt4UDlQUHJFTkEzTnJ2azZmZmRObGhvYUErbHd6V3UvK25BPT0iLCJpdiI6ImYxMTRiNjNhODI2YzgyNjgyODlmZjA3MTA4Y2MwNTE1In0=_1736704189638)]
- **Taming irregular EDA applications on GPUs**. *Yangdong Deng, Bo David Wang, Shuai Mu, IEEE International Conference on Computer-Aided Design (ICCAD), 2009* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5361242)] ![](https://img.shields.io/badge/ICCAD2009-orange)
- **Parallel GMRES solver for fast analysis of large linear dynamic systems on GPU platforms**. *Kai He, Sheldon X.-D. Tan, Hengyang Zhao, Xue-Xin Liu, Hai Wang, Guoyong Shi, Integration, 2016* [[pdf](https://pdf.sciencedirectassets.com/271564/1-s2.0-S0167926015X00046/1-s2.0-S016792601500084X/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEPL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQCtOJKq91y%2FNZOubVsx08tAHhLJMi2iSPQriWron7CcAwIgHr6RdjZbXkDfwqKh32ux224pQd3BoK7eMbM9ZkGnEzMquwUI2%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDEgjWOXhZLBugxPZ8yqPBT5sy02to9heNjREKTxeBVVY4n6mpjBty5EHr1aGulMzJeRsYcEMArpF%2FmcQ%2BCqZc1n%2F%2BBYLwUG4Sbdh%2FiK44nk1JSfUsDjriaTUJLKi4JuJczKhsibiObJu56GgqmMC1DvoAw4YllN8gcEKbnIqIODHHCL81kw4PQ8wA6DdJSMKQ9LXCE6s%2FqAAji7z2k3ek5Z2SS3nEDKTTQms5RkF%2BRbP%2B1viYcec5uISooS9Yi4XxpYOMvzebhiarJI8%2B3BtEpeoqCbXSH4ORrOCg%2BFUcNO6b7on2lcfb9FFyKPLjWkawIG3MWMNNdiLP%2Bo8Y%2BYG8wcqjTF1S%2Fvw4pyFGNLzonjShe9oq9baYriBIO7l0%2FrTd%2BZzRsHBqT8dWAZPPGoTkss%2BuMR1pAckcjMNsQzi9lQWZ1OO%2F3ndYCeqFqDDaHgcKT5djFr5SFfBsvE4uIu870pzbgpgcv4ybQXnKHfGwU3MYNRP%2BGHxQNTuqHUwjqNj2DRdSQwMjorzwfy1%2BcpOQHVItRfvWEz7QorCGCEHTgwD3pDGb%2B7EKkVeKZuA4vF%2FWWHTCdHByBVxIILT7319IMI1Dat5gVL3bfwW85GLabOdXyPCqVK48Pa6Vnm2dgK36vLlb2jBWkEmynldai%2FqVtLBoUd%2F0BOgCsT9bwcgwAwCzx0wqyO9gLVN7%2BIpa1KCmlvQTFeUgKWqfjdWMvfvgzrI0D5r%2FwzJnjOdVj0hc%2B0%2BCOm%2BtNFrD9UZl6JHx1tZZaS1oBjdZnGbfdhxXTDaiFPu%2BqtaXhDdyw1Qf%2FjFLcm6MJHVybReJQC3XROjPZrkfrB7s7NOa3kDxv3IPWGWCaYDHqRHHiRIU4J8gSnbArwKx9lI1kwd88zRZUdAifMw6vWPvAY6sQHpfbEdl6SD7E2dW3NUj1Tv5HVzuy%2BHVHgZ%2FlxqA%2BgtccAdN3AJ5h4d5fpocC2Pxhxhz7TzxfUqJbBKPl6uXckVAVPnfHolBhpPPZRUQUHPo2UL796SCN64HR4ABoZwCVvkaK2mo61trtPuLhm4A%2Baru%2BnpTOrUjoxd1vQazWoJq2lnEJlDhKlaIagyf97zDZr9G%2FdRHtoCzFLgK%2BFKyooIOyHC7oDWPJfolS8tCa2O76c%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250112T182625Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYT53EKV72%2F20250112%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=15bd756d05e2cc3a540524af79c6f157d575f73da7eb38100090d8adff069a02&hash=4cca483debead131d895a41eaedbe4d3c652756461a415d92ca8c8ed80225e39&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S016792601500084X&tid=spdf-8a85978f-46df-447d-9384-a3c9d587b405&sid=26a7a81e1ae7134edf588830a05124f237b6gxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=0a0e58555200525601&rr=900f31d98aebe69a&cc=hk&kca=eyJrZXkiOiJoQTFNa3NKSXdlRDc5Ums0ejBWSkhZVmlaMUFKYlNaVUUvVHZGSGNNd3JKSDAvSnAydWlTSVc4eEptUW9DNTZUWnVRc2gwNWJrTXE5dThadkZDWFZhM1ArL1N4SlZzOWFyNmt3c2p4R0R1bG0xSGJWNmlBQVl0NzRCd3duQVZRSFZ0RWVteHRJVGh3U0FDcVQ0QmM0aWZCTnJGZGFBMk4yVmZoZVA4aDc2aEVYYXZLNyIsIml2IjoiZWIyYjI0MjFhYWE5MTEyZWMzYjE0MmVhZTczMzc3NDcifQ==_1736706396576)] ![](https://img.shields.io/badge/Integration2016-orange)
- **Sparse Matrix Computations on Manycore GPU’s**. *Michael Garland, Design Automation Conference (DAC), 2008* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4555771)] ![](https://img.shields.io/badge/DAC2008-orange)
- **VCSR: An Efficient GPU Memory-Aware Sparse Format**. *Elmira Karimi, Nicolas Bohm Agostini, Shi Dong, David Kaeli, IEEE Transactions on Parallel and Distributed Systems (IEEE Trans Parallel Distrib Syst), 2022* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9787804)]
- **Optimization of Sparse Matrix-Vector Multiplication for CRS Format on NVIDIA Kepler Architecture GPUs**. *Daichi Mukunoki, Daisuke Takahashi, Computational Science and Its Applications (ICCSA), 2013* [[DOI](https://link.springer.com/chapter/10.1007/978-3-642-39640-3_15)] ![](https://img.shields.io/badge/ICCSA2013-orange)
- **DASP: Specific Dense Matrix Multiply-Accumulate Units Accelerated General Sparse Matrix-Vector Multiplication**. *Yuechen Lu, Weifeng Liu, Supercomputing Conference (SC), 2023* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10485119)] ![](https://img.shields.io/badge/SC2023-orange)
- **Model-driven autotuning of sparse matrix-vector multiply on GPUs**. *Jee Whan Choi, Amik Singh, Richard W. Vuduc, ACM SIGPLAN Notices (ACM SIGPLAN Not), 2010* [[pdf](https://vuduc.org/pubs/choi2010-gpu-spmv.pdf)] ![](https://img.shields.io/badge/ACMSIGPLANNot2010-orange)
- **LightSpMV: Faster CSR-based sparse matrix-vector multiplication on CUDA-enabled GPUs**. *Yongchao Liu, Bertil Schmidt, International Conference on Application Specific Systems, Architectures and Processors (ASAP), 2015* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7245713)] ![](https://img.shields.io/badge/ASAP2015-orange)
- **LightSpMV: Faster CUDA-Compatible Sparse Matrix-Vector Multiplication Using Compressed Sparse Rows**. *Yongchao Liu, Bertil Schmidt, Journal of Signal Processing Systems (J Signal Process Syst), 2018* [[DOI](https://dl.acm.org/doi/abs/10.1007/s11265-016-1216-4)]
- **TileSpMV: A Tiled Algorithm for Sparse Matrix-Vector Multiplication on GPUs**. *Yuyao Niu, Zhengyang Lu, Meichen Dong, Zhou Jin, Weifeng Liu, Guangming Tan, International Symposium on Parallel and Distributed Processing (IPDPS), 2021* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9460505)] ![](https://img.shields.io/badge/IPDPS2021-orange)
- **Auto-Tuning CUDA Parameters for Sparse Matrix-Vector Multiplication on GPUs**. *Ping Guo, Liqiang Wang, International Conference on Computational and Information Sciences (ICCIS), 2010* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5709485)] ![](https://img.shields.io/badge/ICCIS2010-orange)
- **Automatically generating and tuning GPU code for sparse matrix-vector multiplication from a high-level representation**. *Dominik Grewe, Anton Lokhmotov, Proceedings of the Fourth Workshop on General Purpose Processing on Graphics Processing Units (GPGPU), 2011* [[pdf](https://ece.northeastern.edu/groups/nucar/GPGPU4/files/grewe.pdf)] ![](https://img.shields.io/badge/GPGPU2011-orange)
  
#### Multiple GPU

### FPGA

### Processing in Memory
- **SpaceA: Sparse Matrix Vector Multiplication on Processing-in-Memory Accelerator**. *Xinfeng Xie, Zheng Liang, Peng Gu, Abanti Basak, Lei Deng, Ling Liang, IEEE Symposium on High-Performance Computer Architecture (HPCA), 2021* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9407163)] ![](https://img.shields.io/badge/HPCA2021-orange)
- **ABC-DIMM: Alleviating the Bottleneck of Communication in DIMM-based Near-Memory Processing with Inter-DIMM Broadcast**. *Weiyi Sun, Zhaoshi Li, Shouyi Yin, Shaojun Wei, Leibo Liu, Annual International Symposium on Computer Architecture (ISCA), 2021* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9499805)] ![](https://img.shields.io/badge/ISCA2021-orange)
- **SparseP: Towards Efficient Sparse Matrix Vector Multiplication on Real Processing-In-Memory Architectures**. *Christina Giannoula, Ivan Fernandez, Juan Gómez Luna, Nectarios Koziris, Georgios Goumas, Onur Mutlu, Proceedings of the ACM on Measurement and Analysis of Computing Systems (POMACS), 2022* [[DOI](https://dl.acm.org/doi/10.1145/3508041)] [[code](https://github.com/CMU-SAFARI/SparseP)] ![](https://img.shields.io/badge/POMACS2022-orange)

### Heterogeneous Platform

### Distributed Platform

